NNLM
https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9



http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf
怎么这么难懂...
https://medium.com/@satyavasanth_57235/yoshua-bengios-a-neural-probabilistic-language-model-in-500-words-665b6e64ade6

怎样理解 Curse of Dimensionality（维数灾难）
https://zh.wikipedia.org/wiki/%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE
https://www.zhihu.com/question/27836140

### distributed representation 

(分散式表示)向量的每一维都表示文本的某种潜在的语法或语义特征
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
https://www.zhihu.com/question/45027109/answer/129387065
https://zhuanlan.zhihu.com/p/22386230
[![Foo](https://pic1.zhimg.com/80/d6a33408a8bf47e3af5b3f9623233fd4_720w.jpg)](https://zhuanlan.zhihu.com/p/22386230)

### Hyperbolic Tangent

tanhtanh为双曲正切函数，其英文读作Hyperbolic Tangent。tanh和 sigmoid 相似，都属于饱和激活函数，区别在于输出值范围由 (0,1) 变为了 (-1,1)，可以把 tanh 函数看做是 sigmoid 向下平移和拉伸后的结果。
https://zhuanlan.zhihu.com/p/73214810




